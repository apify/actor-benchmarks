name: Crawler benchmarks cron
# Workaround for `schedule` not supporting input parameters.

on:
  schedule:
    - cron: '0 0 * * *'


jobs:
  http-crawlers:
    name: Http crawlers benchmarks
    uses: ./.github/workflows/crawler_benchmarks.yaml
    with:
      crawler_name_pattern: .*(cheerio)|(parsel).*
      crawler_input: >
        {
        "startUrls":[{"url":"http://127.0.0.1:8080"}],
        "exclude":["https://**/products/**"],
        "maxRequestsPerCrawl": 2000,
        "proxyConfiguration":{"useApifyProxy": false}
        }
      tag: daily-master
      repetitions: 5
      regenerate_actor_lock_files: true
    secrets: inherit

  long-running-http-crawlers:
    name: Long running Http crawlers benchmarks
    uses: ./.github/workflows/crawler_benchmarks.yaml
    with:
      crawler_name_pattern: .*(cheerio)|(parsel).*
      crawler_input: >
        {
        "startUrls":[{"url":"http://127.0.0.1:8080"}],
        "exclude":["https://**/products/**"],
        "maxRequestsPerCrawl": 10000,
        "proxyConfiguration":{"useApifyProxy": false}
        }
      tag: daily-master-long-running
      repetitions: 1
      regenerate_actor_lock_files: true
    secrets: inherit

  playwright-crawlers:
    name: Playwright crawlers benchmarks
    uses: ./.github/workflows/crawler_benchmarks.yaml
    with:
      crawler_name_pattern: .*playwright.*
      crawler_input: >
        {
        "startUrls":[{"url":"http://127.0.0.1:8080"}],
        "exclude":["https://**/products/**"],
        "maxRequestsPerCrawl": 2000,
        "proxyConfiguration":{"useApifyProxy": false}
        }
      tag: daily-master
      repetitions: 5
      regenerate_actor_lock_files: true
    secrets: inherit
